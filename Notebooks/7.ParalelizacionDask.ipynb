{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Paralelización en Python: Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask es un paquete que nos permite palelizar algunas operaciones de manera sencilla sin necesidad de alterar nuestro código de manera notable. Esto lo logra mediante la partición de los datos en `chunks` o bloques que entran en la memoria de nuestro sistema para su procesado independiente. Su función extiende aún mas las capacidades de numpy y pandas para trabajar con big data y, para nuestro interés, se integra de manera eficiente con xarray para el manejo de _big data_ en geociencias.\n",
    "\n",
    "Antes de abordar el uso en geociencias, vamos a revisar un poco como es que dask funciona sobre los elementos base de numpy y pandas ya que esto nos ayudará a comprender su comportamiento con xarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Dask Arrays\n",
    "\n",
    "Un arreglo de Dask es, en esencia, una combinación de arreglos de numpy los cuales son ordenados en bloques dentro de una grilla. La mayoría de las funciones que numpy ofrece tambien se encuentran disponibles en dask. Las formas disponibles para construir arreglos de dask son iguales a las de numpy con la diferencia que se tiene que especificar el parámetro `chunks` para indicarle a dask como debe de fraccionar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = da.random.random((1000,1000), chunks=(100,100))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la información provista por dask podemos observar como este fraccionamiento sucede junto a cuanto espacio ocupa en la memoria cada bloque. Algo que debemos entender es que si bien parece que hemos creado un arreglo de datos, en realidad solo hemos creado las instrucciones que dask debe seguir para crear los datos. Esta forma de trabajar de dask se denomina _perezosamente_, asi podemos decir que hemos creado un arreglo de manera perezosa.\n",
    "\n",
    "Toda operación realizada sobre este arreglo de dask formara una serie de instrucciones (gráficos computacionales) que se iran agregando en cadena hasta el momento que deseemos realizar los cálculos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = data.mean()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del gráfico computacional obtenido podemos observar que dask va operando individualmente sobre los bloques para luego ir agregando nuestros resultados. Si queremos obtener el resultado deberemos llamar al método `compute` para que se realicen los cálculos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time res.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos trabajar sobre los arreglos de dask tal y como se trabajarían con arreglos de numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (data - data.mean(axis=1, keepdims=True))/data.std(axis=1, keepdims=True)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El grafico computacional es tan grande que mejor sera visualizarlo como pdf\n",
    "res.visualize('norm_dask.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos llamar a `compute` sobre este arreglo para obtener el resultado como arreglo de numpy.\n",
    "\n",
    "Para poder ver el progreso de los calculos realizados por dask haremos uso de `distributed`, una herramienta que consiste de un planificador o _scheduler_ el cual distribuye el trabajo entre varios nodos computacionales de manera eficiente ([más información](https://distributed.dask.org/en/latest/)) el cual puede escalar desde una laptop hasta un cluster. Al usar el módulo `Client` estaremos creando un cluster local en donde cada núcleo de nuestra pc será un trabajador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "# Correr esta celda solo una vez\n",
    "# en caso de ejecutarla mas de una vez\n",
    "# reiniciar el kernel del notebook\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos acceder al link que nos muestra el widget para acceder al panel de información de nuestro cluster local. En caso de tener instalado la extensión de dask para Jupyter, puede acceder a todos estos paneles directamente en Jupyter.\n",
    "\n",
    "Al usar `compute` veremos como dask ejecuta las instrucciones guardadas en el gráfico computacional para otorgarnos el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Procesos personalizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien podemos hacer uso de dask sobre numpy y pandas, muchas veces tenemos funciones que operan de manera individual o bucles los cuales funcionarían mejor si estuvieran paralelizados. Dask permite paralelizar perezosamente bucles y funciones mendiante el decorador `delayed`. ([info](https://docs.dask.org/en/latest/delayed.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo tomado de la documentación de dask\n",
    "# https://docs.dask.org/en/latest/delayed.html\n",
    "import dask\n",
    "\n",
    "@dask.delayed\n",
    "def inc(x):\n",
    "    return x + 1\n",
    "\n",
    "@dask.delayed\n",
    "def double(x):\n",
    "    return x + 2\n",
    "\n",
    "@dask.delayed\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "data = [1, 2, 3, 4, 5]\n",
    "\n",
    "output = []\n",
    "for x in data:\n",
    "    a = inc(x)\n",
    "    b = double(x)\n",
    "    c = add(a, b)\n",
    "    output.append(c)\n",
    "\n",
    "total = dask.delayed(sum)(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Integración con xarray\n",
    "\n",
    "Frecuentemente nos encontramos con registros diarios, mensuales o anuales, guardados en archivos separados, los cuales cubren un periodo extenso de tiempo sobre el cual nos gustaria operar. Gracias a la integración de dask con xarray, esto es facilmente manejable usando la función `open_mfdataset` la cual leerá el metadato de todos nuestros archivos para finalmente otorgarnos un objeto de dask sobre el cual trabajar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# En caso de tener archivos almacenados localmente\n",
    "# reemplazar el string por la ubicación de los datos\n",
    "# data = xr.open_mfdataset(\"PATH/TO/FILES/*.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien podemos leer datos desde la nube de manera perezosa gracias al [catálogo](https://pangeo-data.github.io/pangeo-datastore/index.html) que proporciona el proyecto [Pangeo](http://pangeo.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "cat = intake.Catalog(\"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/ocean.yaml\")\n",
    "copernicus = cat[\"sea_surface_height\"].to_dask()\n",
    "copernicus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestra estructura de xarray se encuentra poblada de metadatos y etiquetas de la manera usual, la unica diferencia es que los datos son arreglos de dask los cuales no han cargado los datos realmente.\n",
    "\n",
    "Este es un ejemplo de _big data_ considerando que nuestras laptops a lo mucho tienen 12GB de memoria. Para comprobar el tamaño de nuestros datos, hacemos uso de la propiedad `nbytes` que xarray hereda de numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Los datos cargados tienen un tamaño de {copernicus.nbytes/1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a realizar algunos ejercicios básicos de selección y agregación para apreciar de primera mano como dask trabaja. Si han ejecutado la celda en donde se declara el `Client` para usar nuestra pc como cluster entonces todas las operaciones que realicemos con dask de ahora en adelante seran ancladas a este distribuidor de tareas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sla = copernicus.sla\n",
    "sla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sla\n",
    "    .sel(latitude=0, method='nearest')\n",
    "    .sel(longitude=slice(140, 280), time=slice(\"2015-01-01\",\"2015-05-01\"))\n",
    "    .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
